{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbbe152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    return pd.read_csv(path)\n",
    "load_dotenv() \n",
    "data_path = os.getenv(\"DATA\")\n",
    "df = read_data(data_path)\n",
    "data_path2 = os.getenv(\"TRAINING_DATA\")\n",
    "df2 = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop([\"HATSURESI\",\"Unnamed: 0\", \"Unnamed: 0.1\"], axis=1)  \n",
    "y = df2[\"HATSURESI\"]                 \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shape of the resulting splits\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of scheduled departure times in HH:MM format\n",
    "sefer_saatleri = [\n",
    "    \"05:00\", \"05:10\", \"05:20\", \"05:30\", \"05:38\", \"05:45\", \"05:52\", \"06:00\", \"06:07\", \"06:14\",\n",
    "    \"06:21\", \"06:28\", \"06:35\", \"06:42\", \"06:49\", \"06:56\", \"07:03\", \"07:10\", \"07:17\", \"07:24\",\n",
    "    \"07:31\", \"07:38\", \"07:45\", \"07:52\", \"08:00\", \"08:08\", \"08:16\", \"08:24\", \"08:32\", \"08:40\",\n",
    "    \"08:50\", \"09:00\", \"09:10\", \"09:20\", \"09:28\", \"09:36\", \"09:44\", \"09:52\", \"10:00\", \"10:08\",\n",
    "    \"10:16\", \"10:24\", \"10:32\", \"10:40\", \"10:48\", \"10:56\", \"11:04\", \"11:12\", \"11:20\", \"11:28\",\n",
    "    \"11:36\", \"11:44\", \"11:52\", \"12:00\", \"12:08\", \"12:16\", \"12:24\", \"12:32\", \"12:40\", \"12:48\",\n",
    "    \"12:56\", \"13:04\", \"13:12\", \"13:20\", \"13:28\", \"13:36\", \"13:44\", \"13:52\", \"14:00\", \"14:08\",\n",
    "    \"14:16\", \"14:24\", \"14:32\", \"14:40\", \"14:48\", \"14:56\", \"15:04\", \"15:12\", \"15:20\", \"15:28\",\n",
    "    \"15:36\", \"15:44\", \"15:52\", \"16:00\", \"16:10\", \"16:20\", \"16:30\", \"16:39\", \"16:48\", \"16:57\",\n",
    "    \"17:06\", \"17:15\", \"17:26\", \"17:35\", \"17:44\", \"17:53\", \"18:02\", \"18:11\", \"18:20\", \"18:29\",\n",
    "    \"18:38\", \"18:47\", \"18:56\", \"19:05\", \"19:14\", \"19:23\", \"19:32\", \"19:41\", \"19:50\", \"19:59\",\n",
    "    \"20:10\", \"20:20\", \"20:30\", \"20:40\", \"20:50\", \"21:00\", \"21:10\", \"21:20\", \"21:30\", \"21:45\",\n",
    "    \"22:00\", \"22:15\", \"22:30\", \"22:45\", \"23:00\", \"23:15\", \"23:30\", \"23:45\", \"00:00\"\n",
    "]\n",
    "\n",
    "base_date = \"2025-04-07\"  # Reference date for all times\n",
    "\n",
    "# Combine date and time to create full datetime entries\n",
    "tarihli_saatler = [pd.to_datetime(f\"{base_date} {s}\") for s in sefer_saatleri]\n",
    "\n",
    "# Create a DataFrame and extract time-based features\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp[\"HATBASLANGICTARIHI\"] = tarihli_saatler  # Full datetime\n",
    "df_temp[\"HOUR\"] = df_temp[\"HATBASLANGICTARIHI\"].dt.hour  # Extract hour\n",
    "df_temp[\"MONTH\"] = df_temp[\"HATBASLANGICTARIHI\"].dt.month  # Extract month\n",
    "df_temp[\"DAY_OF_WEEK\"] = df_temp[\"HATBASLANGICTARIHI\"].dt.weekday  # Day of the week (0 = Monday)\n",
    "\n",
    "# Create one-hot encoding for day of week (excluding Monday = 0)\n",
    "for i in range(1, 7):\n",
    "    df_temp[f\"DAY_OF_WEEK_{i}\"] = (df_temp[\"DAY_OF_WEEK\"] == i).astype(int)\n",
    "\n",
    "# Create one-hot encoding for month (excluding January = 1)\n",
    "for m in range(2, 13):\n",
    "    df_temp[f\"MONTH_{m}\"] = (df_temp[\"MONTH\"] == m).astype(int)\n",
    "\n",
    "# Add constant feature values representing external conditions\n",
    "df_temp[\"HOLIDAY_CATEGORY_Normal\"] = 1\n",
    "df_temp[\"PANDEMIC_CONDITION_Pandemic\"] = 0\n",
    "df_temp[\"SCHOOL_STATUS_School Open\"] = 1\n",
    "df_temp[\"weather_description_Cloudy\"] = 0\n",
    "df_temp[\"weather_description_Low Visibility\"] = 0\n",
    "df_temp[\"weather_description_Precipitation\"] = 0\n",
    "df_temp[\"weather_description_Storm\"] = 0\n",
    "df_temp[\"weather_temp\"] = 299.15  # Temperature in Kelvin\n",
    "\n",
    "df[\"HATBASLANGICTARIHI\"] = pd.to_datetime(df[\"HATBASLANGICTARIHI\"], errors=\"coerce\")\n",
    "# Get historical averages of HATSURESI grouped by hour and month\n",
    "lag_ortalamalari = (\n",
    "    df\n",
    "    .groupby([df[\"HOUR\"], df[\"HATBASLANGICTARIHI\"].dt.month])[\"HATSURESI\"]\n",
    "    .mean()\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Assign historical lag values to the new data\n",
    "for lag in range(1, 6):\n",
    "    df_temp[f\"HATSURESI_LAG_{lag}\"] = df_temp.apply(\n",
    "        lambda row: lag_ortalamalari.get((row[\"HOUR\"], row[\"MONTH\"]), df[\"HATSURESI\"].mean()),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Drop original day of week column since one-hot encoded version exists\n",
    "df_temp.drop(columns=[\"DAY_OF_WEEK\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define and train the CatBoost model with the best parameters\n",
    "best_cat_model = CatBoostRegressor(\n",
    "    learning_rate=0.1,          # Learning rate\n",
    "    l2_leaf_reg=9,              # L2 regularization\n",
    "    iterations=500,             # Number of boosting rounds\n",
    "    depth=10,                   # Tree depth\n",
    "    border_count=64,            # Number of splits for numeric features\n",
    "    verbose=0,                  # Suppress output\n",
    "    random_state=42             # For reproducibility\n",
    ")\n",
    "best_cat_model.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature column names from the training set\n",
    "feature_columns = X_train.columns.tolist()\n",
    "predictions = []  # List to store predictions for each row\n",
    "\n",
    "# Loop through each row in the prediction dataframe\n",
    "for i in range(len(df_temp)):\n",
    "    # Update LAG features using previous predictions\n",
    "    for lag in range(1, 6):\n",
    "        if i - lag >= 0:\n",
    "            df_temp.at[i, f\"HATSURESI_LAG_{lag}\"] = predictions[i - lag]\n",
    "\n",
    "    # Extract the current row's features and make prediction\n",
    "    X_row = df_temp.loc[i:i, feature_columns]\n",
    "    predicted_value = best_cat_model.predict(X_row)[0]\n",
    "    predictions.append(predicted_value)  # Save prediction for future lags\n",
    "\n",
    "# Store predictions in a new column\n",
    "df_temp[\"PREDICTED_HATSURESI\"] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5283b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hour information\n",
    "df_temp[\"HOUR\"] = df_temp[\"HATBASLANGICTARIHI\"].dt.hour\n",
    "\n",
    "# Filter data from 05:00 until before 00:00 (exclude midnight)\n",
    "df_filtered = df_temp[(df_temp[\"HOUR\"] >= 5) & (df_temp[\"HOUR\"] < 24)]\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot predicted travel durations\n",
    "plt.plot(df_filtered[\"HATBASLANGICTARIHI\"], df_filtered[\"PREDICTED_HATSURESI\"], label=\"Prediction\")\n",
    "\n",
    "plt.title(\"Predicted Trip Durations (05:00â€“00:00)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Line Travel Time (min)\")\n",
    "\n",
    "# Format x-axis to show hours and minutes\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460cf01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
