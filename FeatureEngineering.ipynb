{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee9f52cb",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4920dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fbdca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    return pd.read_csv(path)\n",
    "load_dotenv() \n",
    "data_path = os.getenv(\"CLEANED_DATA\")\n",
    "df = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(dataframe, datetime_columns):\n",
    "    for col in datetime_columns:\n",
    "        dataframe[col] = pd.to_datetime(dataframe[col], errors=\"coerce\")  # Convert to datetime\n",
    "    return dataframe\n",
    "\n",
    "# Assuming the DataFrame is named `df`, identify the datetime columns\n",
    "datetime_columns = [\n",
    "    \"DURAKGIRISTARIHI\",\n",
    "    \"DURAKCIKISTARIHI\",\n",
    "    \"HATBASLANGICTARIHI\",\n",
    "    \"HATBITISTARIHI\",\n",
    "    \"INSERTDATE\",\n",
    "]\n",
    "\n",
    "# Convert datetime columns in the DataFrame\n",
    "df = convert_to_datetime(df, datetime_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Extracts date-related features from the 'HATBASLANGICTARIHI' column.\n",
    "\n",
    "    Specifically, it adds new columns to the DataFrame:\n",
    "    - 'DAY_OF_WEEK': Day of the week as an integer (Monday=0, Sunday=6)\n",
    "    - 'MONTH': Month number (1 to 12)\n",
    "    - 'HOUR': Hour of the day (0 to 23)\n",
    "\n",
    "    These features are commonly used in time-based modeling or analysis.\n",
    "    \"\"\"\n",
    "    df['DAY_OF_WEEK'] = df['HATBASLANGICTARIHI'].dt.weekday\n",
    "    df['MONTH'] = df['HATBASLANGICTARIHI'].dt.month\n",
    "    df['HOUR'] = df['HATBASLANGICTARIHI'].dt.hour\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_holiday_info(df):\n",
    "    public_holidays = {\n",
    "\n",
    "        \"\"\"\n",
    "        Adds a new column indicating whether each route date falls on a public holiday.\n",
    "\n",
    "        The function checks dates in the 'HATBASLANGICTARIHI' column.\n",
    "        If the date matches a predefined Turkish public holiday (2020–2024),\n",
    "        the 'HOLIDAY_CATEGORY' column is set to 'Holiday'; otherwise, it is set to 'Normal'.\n",
    "        \"\"\"\n",
    "\n",
    "        # 2020\n",
    "        '2020-01-01', '2020-04-23', '2020-05-01', '2020-05-19', '2020-05-23', '2020-05-24', '2020-05-25',\n",
    "        '2020-07-15', '2020-07-30', '2020-07-31', '2020-08-01', '2020-08-02', '2020-08-30', '2020-10-29',\n",
    "\n",
    "        # 2021\n",
    "        '2021-01-01', '2021-04-23', '2021-05-01', '2021-05-13', '2021-05-14', '2021-05-15', '2021-07-15',\n",
    "        '2021-07-19', '2021-07-20', '2021-07-21', '2021-07-22', '2021-08-30', '2021-10-29',\n",
    "\n",
    "        # 2022\n",
    "        '2022-01-01', '2022-04-23', '2022-05-01', '2022-05-02', '2022-05-03', '2022-05-04',\n",
    "        '2022-07-08', '2022-07-09', '2022-07-10', '2022-07-11', '2022-07-15', '2022-08-30', '2022-10-29',\n",
    "\n",
    "        # 2023 \n",
    "        '2023-01-01', '2023-04-20', '2023-04-21', '2023-04-22', '2023-04-23',\n",
    "        '2023-06-27', '2023-06-28', '2023-06-29', '2023-06-30',\n",
    "        '2023-05-19', '2023-08-30', '2023-10-29',\n",
    "\n",
    "        # 2024 \n",
    "        '2024-01-01', '2024-04-09', '2024-04-10', '2024-04-11', '2024-04-12',\n",
    "        '2024-06-05', '2024-06-06', '2024-06-07', '2024-06-08', '2024-06-09',\n",
    "        '2024-04-23', '2024-05-19', '2024-08-30', '2024-10-29',\n",
    "    }\n",
    "\n",
    "    df['HOLIDAY_CATEGORY'] = df['HATBASLANGICTARIHI'].dt.strftime('%Y-%m-%d').apply(\n",
    "        lambda x: 'Holiday' if x in public_holidays else 'Normal'\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_pandemic_condition(df, date_column):\n",
    "    \"\"\"\n",
    "    Function that determines pandemic conditions.\n",
    "    Pandemic status is simplified to \"Pandemic\" or \"No Pandemic\".\n",
    "    \"\"\"\n",
    "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
    "    \n",
    "    conditions = [\n",
    "        ((df[date_column] >= '2020-03-16') & (df[date_column] <= '2020-07-03'), 'Pandemic'),\n",
    "        ((df[date_column] >= '2020-03-20') & (df[date_column] <= '2020-06-01'), 'Pandemic'),\n",
    "        ((df[date_column] >= '2021-04-29') & (df[date_column] <= '2021-05-17'), 'Pandemic'),\n",
    "        ((df[date_column] >= '2020-05-23') & (df[date_column] <= '2020-05-25'), 'Pandemic'),\n",
    "        ((df[date_column] >= '2021-05-13') & (df[date_column] <= '2021-05-15'), 'Pandemic'),\n",
    "        ((df[date_column] >= '2020-07-04') & (df[date_column] <= '2020-08-31'), 'Pandemic'),\n",
    "        ((df[date_column] >= '2021-07-19') & (df[date_column] <= '2021-07-23'), 'Pandemic')\n",
    "    ]\n",
    "    \n",
    "    df['PANDEMIC_CONDITION'] = 'No Pandemic'\n",
    "    \n",
    "    for condition, label in conditions:\n",
    "        df.loc[condition, 'PANDEMIC_CONDITION'] = label\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_school_status(df, date_column):\n",
    "    \"\"\"\n",
    "    Function that determines the school status.\n",
    "    The school status is labeled as 'School Open' or 'School Closed'.\n",
    "    \"\"\"\n",
    "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce').dt.normalize()\n",
    "\n",
    "    school_conditions = [\n",
    "        # 2019\n",
    "        ((df[date_column] == '2019-01-01'), 'School Closed'),\n",
    "        ((df[date_column] >= '2019-01-02') & (df[date_column] <= '2019-06-14'), 'School Open'),\n",
    "        ((df[date_column] >= '2019-06-15') & (df[date_column] <= '2019-09-08'), 'School Closed'),\n",
    "        ((df[date_column] >= '2019-09-09') & (df[date_column] <= '2019-12-31'), 'School Open'),\n",
    "\n",
    "        # 2020\n",
    "        ((df[date_column] == '2020-01-01'), 'School Closed'),\n",
    "        ((df[date_column] >= '2020-01-02') & (df[date_column] <= '2020-03-22'), 'School Open'),\n",
    "        ((df[date_column] >= '2020-03-23') & (df[date_column] <= '2020-08-30'), 'School Closed'),\n",
    "        ((df[date_column] >= '2020-08-31') & (df[date_column] <= '2020-12-31'), 'School Open'),\n",
    "\n",
    "        # 2021\n",
    "        ((df[date_column] == '2021-01-01'), 'School Closed'),\n",
    "        ((df[date_column] >= '2021-01-02') & (df[date_column] <= '2021-06-18'), 'School Open'),\n",
    "        ((df[date_column] >= '2021-06-19') & (df[date_column] <= '2021-09-05'), 'School Closed'),\n",
    "        ((df[date_column] >= '2021-09-06') & (df[date_column] <= '2021-12-31'), 'School Open'),\n",
    "\n",
    "        # 2022\n",
    "        ((df[date_column] == '2022-01-01'), 'School Closed'),\n",
    "        ((df[date_column] >= '2022-01-02') & (df[date_column] <= '2022-01-21'), 'School Open'),\n",
    "        ((df[date_column] >= '2022-01-22') & (df[date_column] <= '2022-02-06'), 'School Closed'),\n",
    "        ((df[date_column] >= '2022-02-07') & (df[date_column] <= '2022-06-17'), 'School Open'),\n",
    "        ((df[date_column] >= '2022-06-18') & (df[date_column] <= '2022-09-11'), 'School Open'),\n",
    "        ((df[date_column] >= '2022-09-12') & (df[date_column] <= '2022-12-31'), 'School Open'),\n",
    "\n",
    "        # 2023\n",
    "        ((df[date_column] == '2023-01-01'), 'School Closed'),\n",
    "        ((df[date_column] >= '2023-01-02') & (df[date_column] <= '2023-06-16'), 'School Open'),\n",
    "        ((df[date_column] >= '2023-06-17') & (df[date_column] <= '2023-09-10'), 'School Closed'),\n",
    "        ((df[date_column] >= '2023-09-11') & (df[date_column] <= '2023-12-31'), 'School Open'),\n",
    "\n",
    "        # 2024\n",
    "        ((df[date_column] == '2024-01-01'), 'School Closed'),\n",
    "        ((df[date_column] >= '2024-01-02') & (df[date_column] <= '2024-06-14'), 'School Open'),\n",
    "    ]\n",
    "\n",
    "    \n",
    "    df['SCHOOL_STATUS'] = 'Unknown'\n",
    "\n",
    "    for condition, label in school_conditions:\n",
    "        df.loc[condition, 'SCHOOL_STATUS'] = label\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_weather_data(weather_file):\n",
    "    \"\"\"\n",
    "    Processes weather data.\n",
    "    \"\"\"\n",
    "    df_weather = pd.read_csv(weather_file)\n",
    "    df_weather['dt_iso'] = df_weather['dt_iso'].str.replace(r' \\+0000 UTC$', '', regex=True)\n",
    "    df_weather['dt_iso'] = pd.to_datetime(df_weather['dt_iso'])\n",
    "    return df_weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_weather(date, df_weather):\n",
    "    \"\"\"\n",
    "   Returns the weather information closest to the given date.\n",
    "    \"\"\"\n",
    "    diffs = (df_weather['dt_iso'] - date).abs()\n",
    "    if diffs.empty or diffs.isna().all():\n",
    "        return np.nan\n",
    "    nearest_weather_row = df_weather.iloc[diffs.idxmin()]\n",
    "    return nearest_weather_row[['temp', 'weather_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22bb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_weather_data(df):\n",
    "    \"\"\"\n",
    "    It only simplifies the weather_description column and removes the weather_main column.\n",
    "    \"\"\"\n",
    "\n",
    "    # weather_description sadeleştirilmiş kategoriler\n",
    "    weather_description_mapping = {\n",
    "        'heavy intensity rain': 'Precipitation',\n",
    "        'moderate rain': 'Precipitation',\n",
    "        'light rain': 'Precipitation',\n",
    "        'shower rain': 'Precipitation',\n",
    "        'light shower sleet': 'Precipitation',\n",
    "        'heavy intensity shower rain': 'Precipitation',\n",
    "        'light intensity shower rain': 'Precipitation',\n",
    "        'light shower snow': 'Precipitation',\n",
    "        'sky is clear': 'Clear',\n",
    "        'clear sky': 'Clear',\n",
    "        'few clouds': 'Cloudy',\n",
    "        'scattered clouds': 'Cloudy',\n",
    "        'broken clouds': 'Cloudy',\n",
    "        'overcast clouds': 'Cloudy',\n",
    "        'fog': 'Low Visibility',\n",
    "        'mist': 'Low Visibility',\n",
    "        'haze': 'Low Visibility',\n",
    "        'smoke': 'Low Visibility',\n",
    "        'light snow': 'Precipitation',\n",
    "        'thunderstorm': 'Storm',\n",
    "        'thunderstorm with heavy rain': 'Storm',\n",
    "        'thunderstorm with light rain': 'Storm',\n",
    "        'thunderstorm with rain': 'Storm',\n",
    "        'tornado': 'Storm',\n",
    "        'dust': 'Low Visibility'\n",
    "    }\n",
    "\n",
    "    df['weather_description'] = df['weather_description'].replace(weather_description_mapping)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_weather_data(df, df_weather, date_column):\n",
    "\n",
    "    df_weather = simplify_weather_data(df_weather)\n",
    "    \n",
    "    df[['weather_temp', 'weather_description']] = df[date_column].apply(lambda x: find_nearest_weather(x, df_weather)).apply(pd.Series)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df):\n",
    "    \"\"\"\n",
    "    Converts selected categorical columns into dummy/one-hot encoded variables.\n",
    "\n",
    "    This transformation prepares the data for machine learning models by\n",
    "    converting non-numeric categories into numerical binary columns.\n",
    "    The first category in each column is dropped to avoid multicollinearity.\n",
    "    \"\"\"\n",
    "    categorical_cols = ['DAY_OF_WEEK', 'HOLIDAY_CATEGORY', 'MONTH','PANDEMIC_CONDITION','SCHOOL_STATUS', 'weather_description']\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3572b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(df, lags):\n",
    "    \"\"\"\n",
    "    Creates the 'HATSURESI' feature based on the specified lag (past) times.\n",
    "    \n",
    "    \"\"\"\n",
    "    for lag in lags:\n",
    "       \n",
    "        df[f'HATSURESI_LAG_{lag}'] = df.groupby(\"DURAKSIRANO\")['HATSURESI'].transform(lambda x: x.shift(lag))\n",
    "        df = df.fillna(method='bfill')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f08e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = process_weather_data(r\"C:\\Users\\Excalibur\\Desktop\\Bitirme Projesi\\Datas\\800-last\\weather_condition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a4a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_weather_data(df, df_weather, 'HATBASLANGICTARIHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_data(df)\n",
    "df = add_holiday_info(df)\n",
    "df = categorize_pandemic_condition(df, \"HATBASLANGICTARIHI\")\n",
    "df = categorize_school_status(df, \"HATBASLANGICTARIHI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311039e",
   "metadata": {},
   "source": [
    "#### Categoric Numeric Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_col_names(dataframe, cat_th=15, car_th=20):\n",
    "    \"\"\"\n",
    "    Identifies and categorizes variable types in a DataFrame.\n",
    "\n",
    "    The function classifies variables into:\n",
    "    - Categorical columns (`cat_cols`)\n",
    "    - Numerical columns (`num_cols`)\n",
    "    - Categorical but cardinal columns (`cat_but_car`)\n",
    "    - Numerical but categorical columns (`num_but_cat` — used internally)\n",
    "\n",
    "    Rules:\n",
    "    - Variables with object type are treated as categorical.\n",
    "    - Numerical variables with unique values below `cat_th` are also considered categorical.\n",
    "    - Object-type variables with unique values above `car_th` are considered cardinal and excluded from `cat_cols`.\n",
    "\n",
    "    Returns:\n",
    "    - A list of categorical columns\n",
    "    - A list of numerical columns\n",
    "    - A list of categorical but cardinal columns\n",
    "\n",
    "    Also prints summary statistics about the dataset's structure.\n",
    "    \"\"\"\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtype == \"O\"]\n",
    "    \n",
    "    num_but_cat = [\n",
    "        col\n",
    "        for col in dataframe.columns\n",
    "        if dataframe[col].dtype != \"O\" and dataframe[col].nunique() < cat_th\n",
    "    ]\n",
    "    cat_but_car = [\n",
    "        col\n",
    "        for col in dataframe.columns\n",
    "        if dataframe[col].dtype == \"O\" and dataframe[col].nunique() > car_th\n",
    "    ]\n",
    "\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtype != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "\n",
    "    print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    print(f\"cat_cols: {len(cat_cols)}\")\n",
    "    print(f\"num_cols: {len(num_cols)}\")\n",
    "    print(f\"cat_but_car: {len(cat_but_car)}\")\n",
    "    print(f\"num_but_cat: {len(num_but_cat)}\")\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "    \n",
    "cat_cols, num_cols, cat_but_car = grab_col_names(df)\n",
    "print(cat_cols)\n",
    "print(num_cols)\n",
    "print(cat_but_car)\n",
    "\n",
    "drop_cat_columns = ['HATNO', 'HATKODU', 'DURAKSIRANO', 'DURAKID']\n",
    "cat_cols = [col for col in cat_cols if col not in drop_cat_columns]\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c9ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_lag_features(df, [1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df.drop(['PLAKA', 'HATNO', 'HATKODU', 'DURAKSIRANO', 'DURAKID', 'INSERTDATE', 'DURAKGIRISTARIHI', 'DURAKCIKISTARIHI', 'HATBITISTARIHI'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30315578",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df.drop(['PLAKA', 'HATNO', 'HATKODU', 'DURAKSIRANO', 'DURAKID', 'INSERTDATE', 'DURAKGIRISTARIHI', 'DURAKCIKISTARIHI', 'HATBASLANGICTARIHI', 'HATBITISTARIHI'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
